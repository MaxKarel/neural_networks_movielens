{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.layers import Activation, Lambda\n",
    "from tensorflow.keras.layers import Concatenate, Dense, Dropout\n",
    "from tensorflow.keras.layers import Embedding, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading and imports similar to other workbooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "film size 1682.0\n",
      "user size 943.0\n"
     ]
    }
   ],
   "source": [
    "with open (\"../data/ml-100k/u.data\", \"r\") as f:\n",
    "    data = list(csv.reader(f, delimiter=\"\\t\"))\n",
    "data = np.array(data)\n",
    "film_dim = np.amax(np.array(data[:,1]).astype(np.float))\n",
    "user_dim = np.amax(np.array(data[:,0]).astype(np.float))\n",
    "print(\"film size\", film_dim)\n",
    "print(\"user size\", user_dim)\n",
    "data = data.astype(np.int)\n",
    "data = pd.DataFrame(data)\n",
    "data.sort_values([0,3],inplace=True) ## Sort data\n",
    "data = data.rename(columns= {0: 'user_id',\n",
    "                      1: 'movie_id',\n",
    "                      2: 'rating',\n",
    "                      3: 'time'},\n",
    "            inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the LabelEncoder to transform IDs using a relation (x,y) -> (0,n) where n = # of IDs, so that we do not have IDs just as a random number, but going from 0 to n. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4e848ba11983>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0muser_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id_encoded'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0muser_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id_encoded'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mitem_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "user_encoder = LabelEncoder()\n",
    "data['user_id_encoded'] = user_encoder.fit_transform(data['user_id'].values)\n",
    "user_count = data['user_id_encoded'].nunique()\n",
    "\n",
    "item_encoder = LabelEncoder()\n",
    "data['movie_id_encoded'] = item_encoder.fit_transform(data['movie_id'].values)\n",
    "movie_count = data['movie_id_encoded'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data into test and train sets, but for better performance, we will rescale the ratings to a more Gaussian distribution as regression models tend to work better with normally distributed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90000, 2), (10000, 2), (90000,), (10000,))"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data = data[['user', 'movie']].values\n",
    "Y_data = data['rating'].values\n",
    "\n",
    "y_scaler = StandardScaler().fit(Y_data.reshape(len(Y_data), 1))\n",
    "y_scaled = y_scaler.transform(Y_data.reshape(len(Y_data), 1))[:, 0]\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X_data, y_scaled, test_size=0.1, random_state=315)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select a number of factors for user / movie which we input into the Embedding layer. We also store the minimum and maximum ratings we need to use in the final Lambda layer and we prepare train and test arrays (each containing two arrays for users and for movies IDs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a Recommender model starting with an input layer followed by Embedding layers, one for both movies and users.  We then Concatenate the two Embeddings and follow them by a Dense layer with relu activation function. The final layers contains a Dense layer with a single numeric output, which we need to multiply by a formula to get the desired rating. For this we use the Lambda layer which in fact is not a layer just wraps up a lambda expression to make the model look pretty and consistent - layerlike. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelDenseEmbed(x, y, f):\n",
    "    user = Input(shape=(1,))\n",
    "    movie = Input(shape=(1,))\n",
    "    u = Embedding(x, f)(user)\n",
    "    m = Embedding(y, f)(movie)\n",
    "    x = Concatenate()([u, m])\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(32)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1)(x)\n",
    "    x = Activation('linear')(x)\n",
    "    model = Model(inputs=[user, movie], outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the model and fit it to the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_93\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_195 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_196 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_283 (Embedding)       (None, 1, 100)       94300       input_195[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_284 (Embedding)       (None, 1, 100)       168200      input_196[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 1, 200)       0           embedding_283[0][0]              \n",
      "                                                                 embedding_284[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_110 (Dropout)           (None, 1, 200)       0           concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_114 (Dense)               (None, 1, 32)        6432        dropout_110[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 1, 32)        0           dense_114[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_111 (Dropout)           (None, 1, 32)        0           activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_115 (Dense)               (None, 1, 1)         33          dropout_111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 1, 1)         0           dense_115[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_94 (Lambda)              (None, 1, 1)         0           activation_158[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 268,965\n",
      "Trainable params: 268,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_94\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_197 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_198 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_285 (Embedding)       (None, 1, 100)       94300       input_197[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_287 (Embedding)       (None, 1, 100)       168200      input_198[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_45 (Dot)                    (None, 100, 100)     0           embedding_285[0][0]              \n",
      "                                                                 embedding_287[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_286 (Embedding)       (None, 1, 1)         943         input_197[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_288 (Embedding)       (None, 1, 1)         1682        input_198[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 100, 100)     0           dot_45[0][0]                     \n",
      "                                                                 embedding_286[0][0]              \n",
      "                                                                 embedding_288[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 100, 100)     0           add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_95 (Lambda)              (None, 100, 100)     0           activation_159[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 265,125\n",
      "Trainable params: 265,125\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "decay_rate = 0.001 / 25\n",
    "momentum = 0.5\n",
    "\n",
    "sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate)\n",
    "\n",
    "model = ModelDenseEmbed(user_count, movie_count, 64)\n",
    "model.compile(loss='MSE', optimizer=sgd)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A target array with shape (90000, 1) was passed for an output of shape (None, 100, 100) while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-360-ae941a791f32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model2.fit(x=X_train_array, y=y_train_scaled, batch_size=64, epochs=25,\n\u001b[0;32m----> 2\u001b[0;31m                     verbose=1, validation_data=(X_test_array, y_test_scaled))\n\u001b[0m",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2536\u001b[0m           \u001b[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[0;32m-> 2538\u001b[0;31m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m   2539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2540\u001b[0m       \u001b[0;31m# If sample weight mode has not been set and weights are None for all the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    741\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[1;32m    742\u001b[0m                            \u001b[0;34m' was passed for an output of shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m                            \u001b[0;34m' while using as loss `'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m                            \u001b[0;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                            'as the output.')\n",
      "\u001b[0;31mValueError\u001b[0m: A target array with shape (90000, 1) was passed for an output of shape (None, 100, 100) while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[train_x[:, 0], train_x[:, 1]], y=train_y, batch_size=64, epochs=25, verbose=1, validation_data=([test_x[:, 0], test_x[:, 1]], test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The desired models converges to a loss and val_loss value of abt. 0.66. The loss function used is mean squared error. Since the difference between the max and min of the y_scaled is 3.5, 0.66 can be considered a bit underwhelming result. We can print out some sample data to see the actual numbers (we need to inversely transform the data using the y_scaler instantiated sooner in the code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([test_x[:, 0], test_x[:, 1]])\n",
    "predictions_values = predictions * (max(y_scaled) - min(y_scaled)) + min(y_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(data['rating'])-min(data['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5534458"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(y_scaled)-min(y_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2.7255344]],\n",
       "\n",
       "       [[3.5234368]],\n",
       "\n",
       "       [[1.8686908]],\n",
       "\n",
       "       [[3.32947  ]],\n",
       "\n",
       "       [[3.5301437]],\n",
       "\n",
       "       [[2.9680274]],\n",
       "\n",
       "       [[4.244357 ]],\n",
       "\n",
       "       [[1.6430584]],\n",
       "\n",
       "       [[3.483638 ]],\n",
       "\n",
       "       [[3.753055 ]]], dtype=float32)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_scaler.inverse_transform(predictions[10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3., 1., 1., 3., 4., 5., 5., 3., 4.], dtype=float32)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_scaler.inverse_transform(test_y[10:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
